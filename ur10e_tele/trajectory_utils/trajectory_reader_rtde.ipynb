{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "import h5py\n",
    "import imageio\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "# access individual dictionary keys and values and store in viewable files\n",
    "    # dictionary images (np arrays) get converted into videos\n",
    "        # video 1: \"image\"\n",
    "        # video 2: \"other\" \"hand_image\"\n",
    "    # rest of dictionary gets converted into csv files\n",
    "        # file 1: \"robot_state\"\n",
    "        # file 2: \"controller_info\" and \"task\"\n",
    "        # file 4: \"action\"\n",
    "\n",
    "# hdf5 structure:\n",
    "# HDF5 \"outputs/session_0/episode_0.h5\" {\n",
    "# GROUP \"/\" {\n",
    "# DATASET \"action\" {\n",
    "#     DATATYPE  H5T_IEEE_F64LE\n",
    "#     DATASPACE  SIMPLE { ( 111, 7 ) / ( H5S_UNLIMITED, 7 ) }\n",
    "# }\n",
    "# GROUP \"controller_info\" {\n",
    "#     DATASET \"controller_on\" {\n",
    "#         DATATYPE  H5T_ENUM {\n",
    "#             H5T_STD_I8LE;\n",
    "#             \"FALSE\"            0;\n",
    "#             \"TRUE\"             1;\n",
    "#         }\n",
    "#         DATASPACE  SIMPLE { ( 111 ) / ( H5S_UNLIMITED ) }\n",
    "#     }\n",
    "#     DATASET \"failure\" {\n",
    "#         DATATYPE  H5T_ENUM {\n",
    "#             H5T_STD_I8LE;\n",
    "#             \"FALSE\"            0;\n",
    "#             \"TRUE\"             1;\n",
    "#         }\n",
    "#         DATASPACE  SIMPLE { ( 111 ) / ( H5S_UNLIMITED ) }\n",
    "#     }\n",
    "#     DATASET \"movement_enabled\" {\n",
    "#         DATATYPE  H5T_ENUM {\n",
    "#             H5T_STD_I8LE;\n",
    "#             \"FALSE\"            0;\n",
    "#             \"TRUE\"             1;\n",
    "#         }\n",
    "#         DATASPACE  SIMPLE { ( 111 ) / ( H5S_UNLIMITED ) }\n",
    "#     }\n",
    "#     DATASET \"success\" {\n",
    "#         DATATYPE  H5T_ENUM {\n",
    "#             H5T_STD_I8LE;\n",
    "#             \"FALSE\"            0;\n",
    "#             \"TRUE\"             1;\n",
    "#         }\n",
    "#         DATASPACE  SIMPLE { ( 111 ) / ( H5S_UNLIMITED ) }\n",
    "#     }\n",
    "# }\n",
    "# DATASET \"episode_info\" {\n",
    "#     DATATYPE  H5T_COMPOUND {\n",
    "#         H5T_STRING {\n",
    "#             STRSIZE 100;\n",
    "#             STRPAD H5T_STR_NULLPAD;\n",
    "#             CSET H5T_CSET_ASCII;\n",
    "#             CTYPE H5T_C_S1;\n",
    "#         } \"task\";\n",
    "#         H5T_ENUM {\n",
    "#             H5T_STD_I8LE;\n",
    "#             \"FALSE\"            0;\n",
    "#             \"TRUE\"             1;\n",
    "#         } \"is_success\";\n",
    "#         H5T_STD_I32LE \"episode_id\";\n",
    "#     }\n",
    "#     DATASPACE  SIMPLE { ( 1 ) / ( 1 ) }\n",
    "# }\n",
    "# DATASET \"hand_image\" {\n",
    "#     DATATYPE  H5T_STD_U8LE\n",
    "#     DATASPACE  SIMPLE { ( 111, 640, 480, 3 ) / ( H5S_UNLIMITED, 640, 480, 3 ) }\n",
    "# }\n",
    "# DATASET \"image\" {\n",
    "#     DATATYPE  H5T_STD_U8LE\n",
    "#     DATASPACE  SIMPLE { ( 111, 640, 480, 3 ) / ( H5S_UNLIMITED, 640, 480, 3 ) }\n",
    "# }\n",
    "# DATASET \"robot_state\" {\n",
    "#     DATATYPE  H5T_IEEE_F64LE\n",
    "#     DATASPACE  SIMPLE { ( 111, 15 ) / ( H5S_UNLIMITED, 15 ) }\n",
    "# }\n",
    "# GROUP \"timestamps\" {\n",
    "#     DATASET \"control_start\" {\n",
    "#         DATATYPE  H5T_STD_I64LE\n",
    "#         DATASPACE  SIMPLE { ( 111 ) / ( H5S_UNLIMITED ) }\n",
    "#     }\n",
    "#     DATASET \"policy_start\" {\n",
    "#         DATATYPE  H5T_STD_I64LE\n",
    "#         DATASPACE  SIMPLE { ( 111 ) / ( H5S_UNLIMITED ) }\n",
    "#     }\n",
    "#     DATASET \"sleep_start\" {\n",
    "#         DATATYPE  H5T_STD_I64LE\n",
    "#         DATASPACE  SIMPLE { ( 111 ) / ( H5S_UNLIMITED ) }\n",
    "#     }\n",
    "#     DATASET \"step_end\" {\n",
    "#         DATATYPE  H5T_STD_I64LE\n",
    "#         DATASPACE  SIMPLE { ( 111 ) / ( H5S_UNLIMITED ) }\n",
    "#     }\n",
    "#     DATASET \"step_start\" {\n",
    "#         DATATYPE  H5T_STD_I64LE\n",
    "#         DATASPACE  SIMPLE { ( 111 ) / ( H5S_UNLIMITED ) }\n",
    "#     }\n",
    "# }\n",
    "# }\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_video_file(suffix=\".mp4\", byte_contents=None):\n",
    "#     # Create Temporary File #\n",
    "#     temp_file = tempfile.NamedTemporaryFile(suffix=suffix)\n",
    "#     filename = temp_file.name\n",
    "\n",
    "#     # If Byte Contents Provided, Write To File #\n",
    "#     if byte_contents is not None:\n",
    "#         with open(filename, \"wb\") as binary_file:\n",
    "#             binary_file.write(byte_contents)\n",
    "#     return filename\n",
    "\n",
    "# converts images from ndarray into mp4 video\n",
    "def convert_to_video(images, save_path, fps):\n",
    "    # Create aj for testing, dimension (13, 222, 356, 3)\n",
    "    aj = np.array(images)\n",
    "    # for i in range(aj.shape[0]):\n",
    "    #     cv2.putText(aj[i, :, :], str(i+1), (aj.shape[2]//2-50*len(str(i+1)), aj.shape[1]//2+50), cv2.FONT_HERSHEY_DUPLEX, 5, (255, 30, 30), 10)  # Blue number\n",
    "\n",
    "    # size = 720 * 16 // 9, 720\n",
    "    # duration = 2\n",
    "    # fps = 15\n",
    "    out = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (aj.shape[2], aj.shape[1]))\n",
    "    for i in range(aj.shape[0]):\n",
    "        data = aj[i, :, :, :]\n",
    "        out.write(data)\n",
    "    out.release()\n",
    "    # with imageio.mimwrite(save_path, fps=fps) as vidwriter:\n",
    "    #     for frame in images:\n",
    "    #         vidwriter.append_data(frame)\n",
    "           \n",
    "# save dictionary to csvs   \n",
    "def save_to_csv(obs_dict, path):\n",
    "    for key, value in obs_dict.items():\n",
    "        if isinstance(value, dict): # if value is dictionary, it needs to be merged first and then saved \n",
    "            dataframe = pd.DataFrame(value) # flatten into dataframe with pandas\n",
    "            dataframe.to_csv(os.path.join(path, f\"{key}.csv\"), index=False)\n",
    "        elif isinstance(value, (list, np.ndarray)): # turn list or np array directly to csv file\n",
    "            if isinstance(value, np.ndarray):\n",
    "                value = value.tolist() # turn into list\n",
    "            dataframe = pd.DataFrame(value)\n",
    "            dataframe.to_csv(os.path.join(path, f\"{key}.csv\"), index=False)\n",
    "        else:\n",
    "            # if isinstance(value, np.ndarray) and value.ndim == 1:  # Handle 1D arrays\n",
    "            #     dataframe = pd.DataFrame(value)\n",
    "            dataframe = pd.DataFrame([value])\n",
    "            dataframe.to_csv(os.path.join(path, f\"{key}.csv\"), index=False)\n",
    "\n",
    "# def get_hdf5_length(hdf5_file, keys_to_ignore=[]):\n",
    "#     length = None\n",
    "\n",
    "#     for key in hdf5_file.keys():\n",
    "#         if key in keys_to_ignore:\n",
    "#             continue\n",
    "\n",
    "#         curr_data = hdf5_file[key]\n",
    "#         if isinstance(curr_data, h5py.Group):\n",
    "#             curr_length = get_hdf5_length(curr_data, keys_to_ignore=keys_to_ignore)\n",
    "#         elif isinstance(curr_data, h5py.Dataset):\n",
    "#             curr_length = len(curr_data)\n",
    "#         else:\n",
    "#             raise ValueError\n",
    "\n",
    "#         if length is None:\n",
    "#             length = curr_length\n",
    "#         assert curr_length == length\n",
    "\n",
    "#     return length\n",
    "\n",
    "# convert hdf5 back into a nested dictionary\n",
    "def load_hdf5_to_dict(hdf5_file, keys_to_ignore=[]):\n",
    "    data_dict = {}\n",
    "\n",
    "    print(list(hdf5_file.keys()))\n",
    "\n",
    "    for key in hdf5_file.keys():\n",
    "        if key in keys_to_ignore:\n",
    "            continue\n",
    "\n",
    "        curr_data = hdf5_file[key]\n",
    "        if isinstance(curr_data, h5py.Group): # ungroup nested hdf5 groups\n",
    "            data_dict[key] = load_hdf5_to_dict(curr_data, keys_to_ignore=keys_to_ignore)\n",
    "        elif isinstance(curr_data, h5py.Dataset):\n",
    "            data_dict[key] = np.array(curr_data)\n",
    "        else:\n",
    "            raise ValueError\n",
    "\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trajectory_process(obs_file, output_dir):\n",
    "    # make output_dir if not existing\n",
    "    os.makedirs(output_dir, exist_ok = True)\n",
    "    \n",
    "    # extract dictionary from the hdf5 file\n",
    "    obs_dict = load_hdf5_to_dict(obs_file)\n",
    "    \n",
    "    # first process images from the dictionary into videos\n",
    "    fps = 30 # video fps constant\n",
    "    \n",
    "    if \"image\" in obs_dict.keys(): # write primary images to video\n",
    "        primary_img = obs_dict[\"image\"]\n",
    "        save_path = os.path.join(output_dir, \"primary_cam.mp4\")\n",
    "        convert_to_video(primary_img, save_path, fps=fps)\n",
    "        \n",
    "    if \"wrist_image\" in obs_dict.keys(): # write wrist images to video\n",
    "        wrist_img = obs_dict[\"wrist_image\"]\n",
    "        save_path = os.path.join(output_dir, \"wrist_cam.mp4\")\n",
    "        convert_to_video(wrist_img, save_path, fps = fps)\n",
    "    \n",
    "    # process action and robot_state data into csv files\n",
    "    # if \"task\" in obs_dict.keys(): # print the task string\n",
    "    #     print(obs_dict[\"task\"][0]) # task is the same throughout the whole dictionary\n",
    "    \n",
    "    # create dictionary out of remaining values and write to csv files\n",
    "    # should create 4 csv files: one for robot_state, action, controller_info, and timestamps\n",
    "    other_obs = {key: value for key, value in obs_dict.items() if key not in [\"image\", \"wrist_image\", \"task\"]}\n",
    "    \n",
    "    # print(other_obs)\n",
    "    \n",
    "    save_to_csv(other_obs, output_dir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['action', 'controller_info', 'episode_info', 'image', 'robot_state', 'timestamps', 'wrist_image']\n",
      "['controller_on', 'failure', 'movement_enabled', 'success']\n",
      "['control_start', 'policy_start', 'sleep_start', 'step_end', 'step_start']\n",
      "Done processing.\n"
     ]
    }
   ],
   "source": [
    "hdf5_file = h5py.File(\"/home/demoaccount/Data/demoaccount2/teleop_data_collect/ur10e_tele/outputs/session_1/episode_0.h5\", 'r') # change this to the correct filename\n",
    "\n",
    "# print(hdf5_file.keys())\n",
    "\n",
    "# print(\"action data: {}\".format(hdf5_file['action']))\n",
    "# print(\"action data attributes: {}\".format(list(hdf5_file['action'].attrs)))\n",
    "\n",
    "trajectory_process(hdf5_file, output_dir=\"results/session_1/episode_0\") # change output_dir to the correct name\n",
    "\n",
    "print(\"Done processing.\")\n",
    "\n",
    "# print(load_hdf5_to_dict(hdf5_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MISC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['action', 'controller_info', 'episode_info', 'image', 'robot_state', 'timestamps', 'wrist_image']>\n",
      "[(b'place the stuffy in the box', True, 1)]\n",
      "<HDF5 dataset \"episode_info\": shape (1,), type \"|V105\">\n",
      "[(b'place the pink stuffed animal in the box', True, 1)]\n"
     ]
    }
   ],
   "source": [
    "hdf5_file = h5py.File(\"//home/demoaccount/Data/demoaccount2/teleop_data_collect/ur10e_tele/outputs/stuffed_toy/session_0/episode_1.h5\", 'r+')\n",
    "\n",
    "print(hdf5_file.keys())\n",
    "print(list(hdf5_file['episode_info']))\n",
    "\n",
    "task = \"place the pink stuffed animal in the box\"\n",
    "\n",
    "dtype = np.dtype([('task', 'S100')])\n",
    "\n",
    "data = task.encode('utf-8')\n",
    "\n",
    "# print(data)\n",
    "\n",
    "hdf5_file['episode_info']['task'] = data\n",
    "\n",
    "# hdf5_file.create_dataset('episode_info', data=[(task.encode('utf-8'))], dtype=dtype)\n",
    "\n",
    "print(hdf5_file[\"episode_info\"])\n",
    "print(list(hdf5_file['episode_info']))\n",
    "\n",
    "hdf5_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# class TrajectoryReader:\n",
    "#     def __init__(self, filepath, read_images=True):\n",
    "#         self._hdf5_file = h5py.File(filepath, \"r\")\n",
    "#         # is_video_folder = \"observations/videos\" in self._hdf5_file\n",
    "#         self._read_images = read_images # and is_video_folder\n",
    "#         self._length = get_hdf5_length(self._hdf5_file)\n",
    "#         self._video_readers = {}\n",
    "#         self._index = 0\n",
    "\n",
    "#     def length(self):\n",
    "#         return self._length\n",
    "\n",
    "#     def read_timestep(self, index=None, keys_to_ignore=[]):\n",
    "#         # Make Sure We Read Within Range #\n",
    "#         if index is None:\n",
    "#             index = self._index\n",
    "#         else:\n",
    "#             assert not self._read_images\n",
    "#             self._index = index\n",
    "#         assert index < self._length\n",
    "\n",
    "#         # Load Low Dimensional Data #\n",
    "#         keys_to_ignore = [*keys_to_ignore.copy(), \"videos\"]\n",
    "#         timestep = load_hdf5_to_dict(self._hdf5_file, self._index, keys_to_ignore=keys_to_ignore)\n",
    "\n",
    "#         # Load High Dimensional Data #\n",
    "#         if self._read_images:\n",
    "#             camera_obs = self._uncompress_images()\n",
    "#             timestep[\"observations\"][\"image\"] = camera_obs\n",
    "\n",
    "#         # Increment Read Index #\n",
    "#         self._index += 1\n",
    "\n",
    "#         # Return Timestep #\n",
    "#         return timestep\n",
    "\n",
    "#     def _uncompress_images(self):\n",
    "#         # WARNING: THIS FUNCTION HAS NOT BEEN TESTED. UNDEFINED BEHAVIOR FOR FAILED READING. #\n",
    "#         video_folder = self._hdf5_file[\"observations/videos\"]\n",
    "#         camera_obs = {}\n",
    "\n",
    "#         for video_id in video_folder:\n",
    "#             # Create Video Reader If One Hasn't Been Made #\n",
    "#             if video_id not in self._video_readers:\n",
    "#                 serialized_video = video_folder[video_id]\n",
    "#                 filename = create_video_file(byte_contents=serialized_video)\n",
    "#                 self._video_readers[video_id] = imageio.get_reader(filename)\n",
    "\n",
    "#             # Read Next Frame #\n",
    "#             camera_obs[video_id] = yield self._video_readers[video_id]\n",
    "#             # Future Note: Could Make Thread For Each Image Reader\n",
    "\n",
    "#         # Return Camera Observation #\n",
    "#         return camera_obs\n",
    "\n",
    "#     def close(self):\n",
    "#         self._hdf5_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "teleop_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
